Scenario Use Cache
- Reduce network calls
    - In-memory cache 
- Avoid recomputation
    - avoiding costly recomputation
- Reduce DB load

Cache Policy (Eviction policy) -Storing relevant information in the cache
- LRU - Least Recently Used
    - Least used gets removed in cache
- Avoid Thrashing - when you keep adding and kicking info from cache
    - Worsen performance when your cache is called and never used

Where to place cache
- Cache in server
    - Cache takes up in memory of server
    - If servers fails then in memory cache also fails
    - Cache information varies from server
    - Benefit is extremely fast
- Global cache
    - Slightly slower but has higher accuracy
    - Cache maintains data consistency
    - Limited in size
    - Benefit: Avoid query on database but more on cache
        - You can scale it independently
        - More accurate

Write Through Cache Mechanism
    - Update entry in cache and then updating database
    - Problem: Update in one server cache but not in others
Write-Back Cache Mechanism
    - Evict changed key
    - If key is search then it will hit database and then make an entry in the cache
    - Disadvantage: Very costly to evict and then get from DB (Thrashing might occur)
    - Advantage avoids difference in different cache

Mixed write-though & write back Mechanism
    

